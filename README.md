## ğŸ¦ Loan Approval Prediction using Machine Learning & Streamlit
**Status:** Production-ready â€¢ Fully Tested â€¢ Explainable ML â€¢ Deployable

This repository contains an end-to-end ML solution that predicts whether a home loan application should be **Approved or Rejected** using applicant demographic and financial details. The project follows a complete lifecycle: data preparation, modeling, evaluation, explainability, saving the best pipeline, and deployment through Streamlit.

This project is ideal for:
- Internship submission
- Academic ML demonstration
- GitHub portfolio project
- Deployable real-world prototype  

---

## ğŸ’¡ Business Motivation  

Financial institutions face two critical risks in loan decision-making:

- **Approving loans for financially unstable applicants â†’ Increased default risk and financial loss**
- **Rejecting creditworthy applicants â†’ Missed revenue opportunities and reduced customer trust**

Traditional manual evaluation processes are often:
- Time-consuming  
- Subjective  
- Inconsistent across cases  

This project leverages **Machine Learning** to automate loan assessment in a **fast, objective, and data-driven** manner.  

By analyzing historical patterns and applicant features, the system improves:
- Decision accuracy  
- Operational efficiency  
- Risk management  
- Scalability of loan processing
  
---

## ğŸ¯ ML Problem Statement

- **Task:** Binary Classification  
- **Objective:** Predict `Loan_Status`  
  - `Y` â†’ Approved  
  - `N` â†’ Rejected  
- **Approach:** Supervised Learning  
- **Primary Evaluation Metric:** F1-Score (risk-sensitive)  
- **Secondary Evaluation Metric:** Accuracy  


### ğŸ“Š Why F1-Score Matters

Loan datasets are often slightly imbalanced, meaning one class (approved or rejected) may appear more frequently.

Relying only on **accuracy** can be misleading in such cases.  
The **F1-Score** balances:

- **Precision** â†’ How many approved predictions were actually correct  
- **Recall** â†’ How many eligible applicants were correctly identified  

This makes F1 more suitable for minimizing:
- False approvals (financial loss risk)  
- False rejections (missed business opportunity)  

## ğŸ“Š Dataset Overview  

Total Observations: **615**  
Features: **13 input features** 
Target: **Loan_Status**

### ğŸ”¹ Target Column  

| Column       | Description                          |
|--------------|--------------------------------------|
| Loan_Status  | `Y` â†’ Approved &nbsp;&nbsp; `N` â†’ Rejected |

### ğŸ”¹ Feature Categories  

#### ğŸ‘¤ Applicant Profile  
- Gender  
- Married  
- Dependents  
- Education  
- Self_Employed  

#### ğŸ’° Financial Attributes  
- ApplicantIncome  
- CoapplicantIncome  

#### ğŸ§¾ Loan Parameters  
- LoanAmount (in thousands â‚¹)  
- Loan_Amount_Term (days)  
- Credit_History (1 = Good, 0 = Bad)  

#### ğŸŒ Applicant Context  
- Property_Area (Urban / Semiurban / Rural)

Missing values handled using `SimpleImputer`.

---

## ğŸ” EDA Highlights  

Key insights discovered:

- **Credit History is the strongest predictor of approval.**
- Semi-Urban applicants show the highest approval distribution.
- Applicant income is positively skewed.
- LoanAmount is right-skewed â†’ median imputation preferred.
- Property_Area impacts approval likelihood.
- Rural applicants face slightly lower approval rates.

These patterns shaped model development.

---

## ğŸ¤– Model Engineering  

A unified **Scikit-Learn Pipeline** was used:

### ğŸ§© Preprocessing  
- Numerical â†’ Median Imputation + Standard Scaling  
- Categorical â†’ Mode Imputation + One-Hot Encoding

### ğŸ§ª Trained Models  
The following models were trained and benchmarked:

| Model | Accuracy | F1-Score |
|-------|----------|----------|
| â­ Logistic Regression | **0.8618** | **0.9081** |
| Random Forest | 0.8211 | 0.8764 |
| Gradient Boosting | 0.8049 | 0.8667 |
| Decision Tree | 0.7561 | 0.8235 |

---

## ğŸ¥‡ Selected Model: Logistic Regression  

**Reason for Selection:**
- Best F1-Score (handles imbalance)
- High accuracy
- Strong generalization
- Coefficient-based explainability
- No overfitting indicators  

Serialized model stored in:


---

## ğŸ§® Model Interpretability (XAI)

Using Logistic Regression coefficients:

### ğŸ“ˆ Most Positive Influence
- Credit_History
- Property_Area_Semiurban
- Married_Yes
- Education_Graduate

### ğŸ“‰ Negative Influence
- Dependents_1
- Property_Area_Rural
- Education_Not Graduate

These financial relationships match real-world expectations.

---

## ğŸ–¥ Architecture  

User Input â†’ Streamlit UI â†’ Preprocessing Pipeline
â†’ Trained ML Model â†’ Prediction + Probability Output


Artifacts:
- `/models` â†’ model file
- `/data` â†’ dataset
- Notebook for EDA

---

## ğŸš€ Execution Guide  

Follow these steps to set up and run the project.

### 1ï¸âƒ£ Install Dependencies  
```bash
pip install -r requirements.txt
```

2ï¸âƒ£ Train the Machine Learning Model
```bash
python train_model.py
```

3ï¸âƒ£ Launch the Streamlit Application
```bash
streamlit run app.py
```


## ğŸ§± Project Folder Structure 
```bash
LoanApproval/
â”‚
â”œâ”€â”€ train_model.py
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ loan_eda_and_training.ipynb
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ loan_prediction.csv
â”‚
â””â”€â”€ models/
    â””â”€â”€ loan_approval_model.pkl

```
---

ğŸŒ Deployment Targets

- This project is lightweight and works smoothly on cloud platforms:

- Streamlit Cloud (Recommended)

- HuggingFace Spaces

- Render

- PythonAnywhere

---
## Author

## Dikshitha Anand
AI/ML Developer | Data Science Enthusiast | Adaptive Learner

GitHub: https://github.com/DikshithaAnand

---

## Conclusion

This project demonstrates:

- âœ” Data Preprocessing
- âœ” Feature Engineering
- âœ” Model Benchmarking
- âœ” Explainability (XAI)
- âœ” Serialization
- âœ” Web Application Deployment

---
